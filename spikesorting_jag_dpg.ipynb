{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da11c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aeb324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import datajoint as dj\n",
    "import spyglass as nd\n",
    "from spyglass.common import (Session, IntervalList)\n",
    "import spyglass.spikesorting as ss\n",
    "from spyglass.spikesorting import (SortGroup, \n",
    "                                    SortInterval,\n",
    "                                    SpikeSortingPreprocessingParameters,\n",
    "                                    SpikeSortingRecording, \n",
    "                                    SpikeSorterParameters,\n",
    "                                    SpikeSortingRecordingSelection,\n",
    "                                    ArtifactDetectionParameters,\n",
    "                                    ArtifactRemovedIntervalList,\n",
    "                                  CuratedSpikeSorting)\n",
    "os.chdir(\"/home/jguidera/Src/nwb_custom_analysis/\")\n",
    "from spikesorting_helpers import define_sort_interval_as_interval_list, set_spikesorting_directories\n",
    "from jguidera_spikesorting import return_spikesorting_params\n",
    "from jguidera_reference_electrode import ReferenceElectrode, make_refs_dict\n",
    "from jguidera_brain_region import SortGroupTargetedLocation\n",
    "from populate_jguidera_reference_electrode import populate_jguidera_reference_electrode\n",
    "from vector_helpers import unpack_single_element\n",
    "\n",
    "# Ignore certain warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "# Set directories\n",
    "base_dir = \"/stelmo/nwb/\"\n",
    "(base_dir, raw_dir, analysis_dir, kachery_storage_dir,\n",
    " recording_dir, sorting_dir, waveforms_dir, tmp_dir) = set_spikesorting_directories(base_dir)\n",
    "\n",
    "# set env vars\n",
    "os.environ['spyglass_BASE_DIR'] = str(base_dir)\n",
    "os.environ['spyglass_RECORDING_DIR'] = str(recording_dir)\n",
    "os.environ['spyglass_SORTING_DIR'] = str(sorting_dir)\n",
    "os.environ['spyglass_WAVEFORMS_DIR'] = str(waveforms_dir)\n",
    "os.environ['KACHERY_STORAGE_DIR'] = str(kachery_storage_dir)\n",
    "os.environ['KACHERY_TEMP_DIR'] = str(tmp_dir)\n",
    "os.environ['DJ_SUPPORT_FILEPATH_MANAGEMENT'] = 'TRUE'\n",
    "os.environ['FIGURL_CHANNEL'] = 'franklab2'\n",
    "\n",
    "dj.config[\"enable_python_native_blobs\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d788fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** PARAMETERS ***\n",
    "# NWB file\n",
    "subject_id = \"J16\"\n",
    "date = \"20210531\"\n",
    "# Sort interval\n",
    "starting_interval_list_names = [\"raw data valid times\"] # [\"04_r2\", \"06_r3\"] # use these interval lists and make changes as indicated by flags\n",
    "NO_PREMAZE = True  # True to exclude periods when rat being carried to maze\n",
    "NO_HOME = True  # True to exclude home epochs\n",
    "widen_exclusion_factor = .001  # widen invalid intervals by this many seconds to account for small differences in start and stop of what should be same interval in different IntervalList entries\n",
    "# Sort group\n",
    "sort_group_ids = np.arange(17, 21)\n",
    "set_sort_group_ids_by_targeted_location = True  # True to set sort groups based on targeted locations\n",
    "targeted_locations = [\"CA1\"] # , \"OFC\", \"mPFC\"]  # only used if set_sort_group_ids_by_targeted_location is True\n",
    "override_previous_sort_group = False  # True to remake sort group in datajoint table\n",
    "# Preprocessing and spike sorter parameters depending on brain region\n",
    "parameter_set_dict = return_spikesorting_params()\n",
    "# Spike sorter\n",
    "sorter = 'mountainsort4'\n",
    "# Cluster metrics\n",
    "cluster_metrics_list_name = 'franklab_cluster_metrics_09-19-2021'\n",
    "# Automatic curation parameters\n",
    "automatic_curation_parameter_set_name = \"none\"\n",
    "# Lab team\n",
    "team_name = 'JG_DG'\n",
    "# ******************\n",
    "if not isinstance(starting_interval_list_names, list):\n",
    "    raise Exception(\"starting_interval_list_names must be a list\")\n",
    "    \n",
    "# Define nwb file and check that exists in table\n",
    "nwb_file_name = f\"{subject_id}{date}_.nwb\"\n",
    "if len((Session() & {'nwb_file_name': nwb_file_name})) == 0: \n",
    "    raise Exception(\"nwb file not in Session table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a6090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set sort group by shank\n",
    "populate_jguidera_reference_electrode()\n",
    "if override_previous_sort_group or (len(SortGroup & {'nwb_file_name': nwb_file_name}) == 0): \n",
    "    print(\"Setting sort group by shank\")\n",
    "    SortGroup().set_group_by_shank(nwb_file_name=nwb_file_name,\n",
    "                                   references=make_refs_dict(nwb_file_name),\n",
    "                                   omit_ref_electrode_group=True,)\n",
    "                                  # omit_unitrodes=True)\n",
    "from jguidera_task_event import TaskIdentification\n",
    "TaskIdentification.populate({\"nwb_file_name\": nwb_file_name})\n",
    "from populate_jguidera_brain_region import populate_SortGroupTargetedLocation\n",
    "SortGroupTargetedLocation.populate({\"nwb_file_name\": nwb_file_name})\n",
    "if set_sort_group_ids_by_targeted_location:  # define sort groups by targeted location if desired\n",
    "    os.chdir(\"/home/jguidera/Src/nwb_custom_analysis/\")\n",
    "    from jguidera_brain_region import SortGroupTargetedLocation\n",
    "    sort_group_ids = np.concatenate([(SortGroupTargetedLocation() & {\"nwb_file_name\": nwb_file_name,\n",
    "                                  \"targeted_location\": targeted_location}).fetch(\"sort_group_id\") \n",
    "                    for targeted_location in targeted_locations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0150b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define valid times for sort\n",
    "# Populate premaze durations table in case needed\n",
    "from populate_jguidera_premaze_durations import populate_PremazeDurations\n",
    "from jguidera_premaze_durations import PremazeDurations\n",
    "populate_PremazeDurations()\n",
    "from define_interval_list import define_interval_list_through_exclusion\n",
    "interval_list_name, interval_list = define_interval_list_through_exclusion(starting_interval_list_names=starting_interval_list_names,\n",
    "                                                   nwb_file_name=nwb_file_name,\n",
    "                                                   NO_PREMAZE=NO_PREMAZE,\n",
    "                                                   NO_HOME=NO_HOME,\n",
    "                                                   widen_exclusion_factor=widen_exclusion_factor)\n",
    "IntervalList.insert1({\"nwb_file_name\": nwb_file_name,\n",
    "                      \"interval_list_name\": interval_list_name,\n",
    "                     \"valid_times\": interval_list},\n",
    "                     skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sort interval \n",
    "sort_interval_name, sort_interval = define_sort_interval_as_interval_list(interval_list_name,\n",
    "                                                                          interval_list,\n",
    "                                                                          nwb_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_make_ss_recording = True\n",
    "no_spike_sorting = False\n",
    "no_sorting_view = True\n",
    "no_metrics = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f85c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sort_group_id in sort_group_ids:\n",
    "    print(f\"On sort group: {sort_group_id}\")\n",
    "    sort_group_brain_region = SortGroupTargetedLocation().return_sort_group_targeted_location_map(nwb_file_name)[sort_group_id]\n",
    "     \n",
    "    # Spike sorting recording\n",
    "    recording_key = {'nwb_file_name': nwb_file_name,\n",
    "                     'sort_group_id': sort_group_id,\n",
    "                     'sort_interval_name': sort_interval_name,\n",
    "                     'preproc_params_name': parameter_set_dict[\"preproc_params_name\"][sort_group_brain_region],\n",
    "                     'interval_list_name': interval_list_name,\n",
    "                     'team_name': team_name}\n",
    "    SpikeSortingRecordingSelection.insert1(recording_key, skip_duplicates=True)\n",
    "    SpikeSortingRecording.populate([(SpikeSortingRecordingSelection & recording_key).proj()])\n",
    "    if only_make_ss_recording:\n",
    "        continue\n",
    "    \n",
    "    # Artifact detection \n",
    "    targeted_location_sgs = SortGroupTargetedLocation().return_targeted_location_sort_group_map(nwb_file_name)\n",
    "    # Detect artifacts within sort groups for probes\n",
    "    from populate_jguidera_artifact import populate_ArtifactDetectionParameters\n",
    "    populate_ArtifactDetectionParameters()\n",
    "    if sort_group_brain_region in [\"mPFC\", \"OFC\"]:\n",
    "        artifact_key = (nd.spikesorting.SpikeSortingRecording & recording_key).fetch1('KEY')\n",
    "        artifact_key['artifact_params_name'] = parameter_set_dict[\"artifact\"][sort_group_brain_region]\n",
    "        nd.spikesorting.ArtifactDetectionSelection.insert1(artifact_key, skip_duplicates=True)\n",
    "        nd.spikesorting.ArtifactDetection.populate([(nd.spikesorting.ArtifactDetectionSelection & artifact_key).proj()])\n",
    "        artifact_removed_interval_list_name = (nd.spikesorting.ArtifactDetection & artifact_key).fetch1('artifact_removed_interval_list_name')\n",
    "    # Detect artifacts across sort groups for tetrodes\n",
    "    elif sort_group_brain_region in [\"CA1\"]:\n",
    "        from populate_jguidera_artifact import (populate_ArtifactDetectionAcrossSortGroupsParams, \n",
    "                                                populate_ArtifactDetectionAcrossSortGroupsSelection)\n",
    "        from jguidera_artifact import (ArtifactDetectionAcrossSortGroups,\n",
    "                                       ArtifactDetectionAcrossSortGroupsParams,\n",
    "                                       ArtifactDetectionAcrossSortGroupsSelection)\n",
    "        from populate_jguidera_spikesorting import populate_SpikeSortingRecordingCohortParams\n",
    "        from jguidera_spikesorting import (SpikeSortingRecordingCohort, SpikeSortingRecordingCohortParams)\n",
    "        targeted_region = \"CA1\"\n",
    "        sg_ids = targeted_location_sgs[targeted_region]\n",
    "        preproc_params_name = parameter_set_dict[\"preproc_params_name\"][targeted_region]\n",
    "        populate_SpikeSortingRecordingCohortParams(nwb_file_name,\n",
    "                                                   sort_interval_name, \n",
    "                                                   preproc_params_name,\n",
    "                                                   sg_ids,)\n",
    "        SpikeSortingRecordingCohort.populate()\n",
    "        populate_ArtifactDetectionAcrossSortGroupsParams()\n",
    "        populate_ArtifactDetectionAcrossSortGroupsSelection(nwb_file_name=nwb_file_name)\n",
    "        spike_sorting_recording_cohort_param_name = (SpikeSortingRecordingCohortParams & {\"nwb_file_name\": nwb_file_name}).fetch1(\"spike_sorting_recording_cohort_param_name\")\n",
    "        ArtifactDetectionAcrossSortGroups.populate({\"spike_sorting_recording_cohort_param_name\": spike_sorting_recording_cohort_param_name})\n",
    "    else:\n",
    "        raise Exception(f\"Artifact detection not specified for {sort_group_brain_region}\")\n",
    "        \n",
    "    # Spike sorting\n",
    "    sorter_params_name = parameter_set_dict[\"sorter_params_name\"][sort_group_brain_region]\n",
    "    sorting_key = (nd.spikesorting.SpikeSortingRecording & recording_key).fetch1('KEY')\n",
    "    artifact_removed_interval_list_name = (ArtifactRemovedIntervalList & {\"nwb_file_name\": nwb_file_name, \n",
    "                              \"sort_group_id\": sort_group_id,\n",
    "                              \"sort_interval_name\": sort_interval_name}).fetch1(\"artifact_removed_interval_list_name\")\n",
    "    sorting_key.update({'sorter': sorter,\n",
    "                   'sorter_params_name': sorter_params_name,\n",
    "                   'artifact_removed_interval_list_name': artifact_removed_interval_list_name})\n",
    "    nd.spikesorting.SpikeSortingSelection.insert1(sorting_key, skip_duplicates=True)\n",
    "    if not no_spike_sorting:\n",
    "        nd.spikesorting.SpikeSorting.populate(sorting_key)\n",
    "    curation_key = nd.spikesorting.Curation.insert_curation(sorting_key)\n",
    "    \n",
    "    # waveforms\n",
    "    ss.WaveformParameters().insert_default()\n",
    "    waveform_params_names = ['default_not_whitened', 'default_whitened']\n",
    "    for waveform_params_name in waveform_params_names:\n",
    "        waveform_key = curation_key.copy()\n",
    "        waveform_key.update({'waveform_params_name': waveform_params_name})\n",
    "        ss.WaveformSelection.insert1(waveform_key, skip_duplicates=True)\n",
    "        ss.Waveforms.populate([(ss.WaveformSelection & waveform_key).proj()])\n",
    "    wp = ss.WaveformParameters().fetch()\n",
    "    \n",
    "    if not no_metrics: \n",
    "        # metrics\n",
    "        metric_params = {'peak_offset' : {'peak_sign' : 'neg'}}\n",
    "        metric_params_name = 'DPG_just_peak_offset'\n",
    "        ss.MetricParameters.insert1({'metric_params_name' : metric_params_name,\n",
    "                                                 'metric_params' : metric_params},\n",
    "                                                 skip_duplicates=True)\n",
    "        metrics_params_name_dict = {'default_not_whitened': 'DPG_just_peak_offset',\n",
    "                                    'default_whitened': \"JG_DG_no_peak_offset_min_spikes\"}\n",
    "        metric_key = waveform_key.copy()\n",
    "        for waveform_params_name in waveform_params_names:\n",
    "            metric_key['metric_params_name'] =  metrics_params_name_dict[waveform_params_name]\n",
    "            metric_key['waveform_params_name'] = waveform_params_name\n",
    "            ss.MetricSelection.insert1(metric_key, skip_duplicates=True)\n",
    "            ss.QualityMetrics.populate([(ss.MetricSelection & metric_key).proj()])\n",
    "\n",
    "        # automatic curation\n",
    "        ss.AutomaticCurationParameters().insert_default()\n",
    "        auto_curation_params_name = 'JG_DG_AutoCuration_params'\n",
    "        label_params = {'nn_noise_overlap' : ['>', 0.03, ['noise','reject']],\n",
    "                        'isi_violation' : ['>', 1/400, ['noise','reject']]}\n",
    "        ss.AutomaticCurationParameters().insert1({'auto_curation_params_name' : auto_curation_params_name,\n",
    "                                                  'merge_params' : {},\n",
    "                                                  'label_params' : label_params}, skip_duplicates=True)\n",
    "        autocuration_key = metric_key.copy()\n",
    "        autocuration_key['auto_curation_params_name'] = auto_curation_params_name\n",
    "        ss.AutomaticCurationSelection.insert1(autocuration_key, skip_duplicates=True)\n",
    "        ss.AutomaticCuration.populate([(ss.AutomaticCurationSelection & autocuration_key).proj()])\n",
    "\n",
    "        auto_curation_id = (ss.AutomaticCuration & autocuration_key).fetch1('auto_curation_key')\n",
    "        auto_curation_out_key = (ss.Curation & auto_curation_id).fetch1(\"KEY\")\n",
    "\n",
    "        # add to sortingview workspace for manual curation\n",
    "        if not no_sorting_view: \n",
    "            ss.SortingviewWorkspaceSelection.insert1(auto_curation_out_key, skip_duplicates=True)\n",
    "            ss.SortingviewWorkspace.populate(auto_curation_out_key)\n",
    "            ss.SortingviewWorkspace().url(auto_curation_out_key)\n",
    "\n",
    "        # Populate CuratedSpikeSorting\n",
    "        ss.CuratedSpikeSortingSelection.insert1(auto_curation_out_key, skip_duplicates=True)\n",
    "        ss.CuratedSpikeSorting.populate(auto_curation_out_key)\n",
    "        ss.CuratedSpikeSorting.Unit & auto_curation_out_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d302c2c8-4f73-4293-937a-f0692bcc3904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9611276-f0cd-49ce-b803-4931bc7dbf09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662e949-4aa9-428b-b930-b13a563b1d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca20e03-1004-4619-8616-76be68b5f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spyglass] *",
   "language": "python",
   "name": "conda-env-spyglass-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
